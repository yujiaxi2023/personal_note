![[Chen 等 - 2022 - Remote Sensing Image Change Detection With Transfo.pdf]]



变化检测（CD）是遥感（RS）的主要议题之一，其目标是通过比较不同时间拍摄的同一区域的图像，为每个像素分配二元标签（即，变化或无变化）。随着高分辨率（HR）卫星数据和航空数据的可用性，基于 HR 光学 RS 图像的 CD 提出了两个挑战：场景中对象的复杂性以及不同的成像条件。深度卷积神经网络（CNN）由于其强大的判别能力，已成功应用于 RS 图像分析，并在 CD 任务中显示出良好的性能。

为了解决这些挑战，我们引入了双时域图像变换器（BIT），以有效且高效地模拟双时域图像中的长范围上下文。我们的直觉是，所关注变化的高层次概念可以由少数视觉词，即语义标记，来表示。我们的 BIT 将输入图像表示为少数高层次语义标记，并在紧凑的基于标记的空间-时间中模拟上下文。然后，我们使用浅层 CNN 从两个精炼的特征图中计算特征差异图像（FDI），并将它们输入到浅层 CNN 中以产生像素级的变化预测。

我们的工作贡献可概括如下。1）提出了一种有效的基于变换器的 RS 图像 CD 方法。我们将变换器引入 CD 任务，以更好地模拟双时域图像内的上下文，这有利于识别关注的变化并排除无关的变化。2）我们的 BIT 将输入图像表示为少数视觉词，即标记，并在紧凑的基于标记的空间-时间中模拟上下文。3）在三个 CD 数据集上的广泛实验验证了所提方法的有效性和效率。我们将 ResNet18 的最后一个卷积阶段替换为 BIT，结果的 BIT 基础模型以显著的边际优于纯卷积对手，只使用三倍较低的计算成本和模型参数。

 这篇文章的主要目的是以高效且有效的方式学习和利用双时相图像中的全局语义信息，以提升变化检测（Change Detection, CD）的性能。与现有的基于注意力的CD方法不同，我们从图像中提取一些语义标记（tokens），并在标记基的空间-时间中建模上下文。我们的直觉是，场景中的关注变化可以由一些视觉词（标记）描述，每个像素的高级特征可以由这些语义标记的组合表示。因此，我们的方法展现出了高效率和高性能。

我们的模型采用了在自然语言处理（NLP）领域广泛应用的Transformer模型。近年来，transformer在计算机视觉（CV）领域的应用趋势日益明显，其强大的表示能力使得transformer基模型在各种视觉任务中表现出与卷积模型相当甚至更好的性能。这种令人震惊的性能引起了遥感（RS）社区对其在RS任务中的应用的研究兴趣。

在这篇文章中，我们探索了transformers在二元CD任务中的潜力。我们提出的基于BIT的方法在空间-时间中建模全局语义关系方面效率高且有效，并有助于改变相关特征的表示。

我们的BIT模型包含三个主要组件：1）一个孪生语义标记器，将像素分组成概念以生成每个时态输入的紧凑语义标记集；2）一个Transformer编码器（TE），在基于标记的空间-时间中建模语义概念的上下文；以及3）一个孪生TD，将相应的语义标记投影回像素空间以获取每个时间的细化特征图。我们的BIT模型的推理详细信息在算法1中展示。

在获取了输入双时相图像的两个语义标记集T1和T2后，我们使用TE模型这些标记之间的上下文。我们的动机是，全局语义关系可以通过transformer在基于标记的空间-时间中得到充分利用，从而为每个时态生成富含上下文的标记表示。

这部分内容详细描述了研究中使用的技术和实验设置。首先，介绍了变换解码器（Transformer Decoder，TD），其用于将含有丰富上下文的令牌（Token）映射回像素空间以获得像素级特征。TD利用每个像素与令牌集的关系得到细化的特征。TD包含多头交叉注意力（Multihead Cross Attention，MA）和MLP块的层，而且移除了多头自注意力（Multihead Self Attention，MSA）模块以减少计算量。

接着，介绍了网络的详细配置。使用修改后的ResNet18作为CNN基础架构，用于提取时序图像特征映射。然后，设置了时序图像转换器（Bitemporal Image Transformer，BIT）的参数，包括令牌长度，TE层和TD层的数量，MSA和MA的头数，以及每个头的通道维度。预测头部分使用了一个非常浅的全卷积网络（FCN）进行变化判别。最后，训练阶段，以最小化交叉熵损失来优化网络参数。

在实验设置部分，使用了三个变化检测（Change Detection，CD）数据集进行实验，包括LEVIR-CD、WHU-CD以及DSIFN-CD。并设置了基线模型和BIT模型进行比较。此外，为了评估提出方法的效率，设定了更轻量级的模型进行比较。

在实现细节部分，模型在PyTorch上实现，并使用一个NVIDIA Tesla V100 GPU进行训练。使用随机梯度下降（SGD）进行模型优化，初始学习率设定为0.01，并在训练200个epoch后线性衰减至0。

在评估指标部分，使用了F1分数作为主要评价指标，同时也报告了精度，召回率，交并比（IoU）以及总体准确率（OA）。最后，与多种最新的方法进行比较，包括纯卷积方法和基于注意力的方法。

本节内容重点介绍了几种变化检测(CD)网络和模型效率及有效性的比较研究。包括：

1. **CD网络**：介绍了多种基于Siamese FCN的CD方法，如DTCDSCN、STANet、IFNet和SNUNet。这些方法通常融合多尺度特征、引入通道和空间注意力机制，以提升特征的判别力。此外，有些方法还采用深度监督来加强中间层特征的辨识能力。

2. **模型性能对比**：在LEVIR-CD、WHU-CD和DSIFN-CD测试集上的综合比较显示，基于BIT的模型在所有数据集上均显著超越其他方法，例如在F1分数上超过STANet 2/1.6/4.7分。该结果强调了即使使用简单的CNN基础架构，BIT模型依然能够通过全局抽象空间时间范围内的上下文建模来增强像素空间的特征表示，从而达到卓越的性能。

3. **模型效率与有效性**：在包含英特尔至强银色4214 CPU和NVIDIA Tesla V100 GPU的计算服务器上测试了各种方法的模型参数、每秒浮点运算次数（FLOPs）和F1/IoU分数。结果表明，基于BIT的模型在保持较低的计算复杂度和模型参数的同时，相较于其他基于注意力的方法，在F1/IoU分数上有显著的提升。

4. **可视化对比与消融研究**：通过图像可视化展示了不同方法在三个数据集上的比较结果，并进行了多种消融实验，以验证不同组件（如TE、分词器、TD）在上下文建模、空间特征池化和跨注意力等方面的有效性。特别指出，上下文建模在BIT中起着关键作用，而消融实验进一步证明了TE中自注意力的重要性。

本节主要内容包括：

1. **参数分析**：研究了标记长度和Transformer的深度对模型性能的影响。实验证明，减少标记长度可以显著提高模型的F1分数，但如果标记长度过短，模型可能会丢失一些有用的信息。Transformer的深度对模型性能的影响不大，但解码器的深度与模型性能正相关。

2. **标记可视化**：利用注意力图展示了标记器如何提取高级语义概念以揭示感兴趣的变化。不同的标记可能关联到不同的语义对象。

3. **网络可视化**：通过展示不同阶段的激活图，使我们更好地理解模型的工作原理。给出了预测头计算特征差异图像和生成变化概率图的示例。

4. **模型效果**：通过实验证明，该模型能够有效地在遥感图像中进行变化检测，比其他使用更复杂结构的方法更有效，且在效率和准确性方面表现优异。


1. Title: Remote Sensing Image Change Detection With Transformers (变换器进行遥感图像变化检测)

2. Authors: Hao Chen, Zipeng Qi, Zhenwei Shi

3. Affiliation: 中国科学院光电研究院

4. Keywords: Change Detection, Remote Sensing, Transformer, Bitemporal Image

5. Urls: Github: None

6. Summary: 

    - (1): 高分辨率遥感图像变化检测在处理场景中对象的复杂性以及不同的成像条件上面临挑战。尽管深度卷积神经网络（Deep Convolutional Neural Networks，DCNN）在遥感图像分析中显示出强大的判别能力，但在处理长距离的空间-时间关系时仍然存在困难。

    - (2): 过去的方法主要使用基于注意力的CD方法，但这些方法在处理大规模高分辨率遥感图像时会遇到计算效率低下的问题。此外，它们往往忽视了图像中的全局语义信息，这对于变化检测任务来说是至关重要的。

    - (3): 该论文提出了一种双时域图像变换器（Bitemporal Image Transformer，BIT）。该方法从图像中提取一些语义标记（tokens），并在标记基的空间-时间中建模上下文。为了将丰富的上下文信息映射回像素空间，研究者使用了变换解码器（Transformer Decoder）。

    - (4): 在LEVIR-CD、WHU-CD和DSIFN-CD数据集上的实验证明，BIT模型在所有数据集上的表现均显著优于其他方法，例如在F1分数上超过STANet 2/1.6/4.7分。这些结果证实了BIT模型能够有效地捕获和利用全局语义信息，进而提升遥感图像变化检测的性能。

