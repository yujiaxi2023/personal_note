![[1-s2.0-S2210670723000781-main.pdf]]

已有的框架是使用UNet作为基础，进行迁移学习，集成遥感和街景特征，模型的mIoU作为评价指标，最高可以达到82%
**我们可以使用transformer的模型也就是DERT作为基础进行迁移学习，评价指标也可以采用mIoU**

通过自注意力机制提高分类效果

**本研究的目标是，结合遥感图像和社交媒体图像代替实地调查评估建筑物在洪水灾害后的损失状况**
使用ResNet-50作为编码器，**添加边缘特征和自注意力模块，将街景和遥感特征融合到解码器中**

过去研究中，可以通过SAR获取建筑物的高度信息，并且可以通过SVM来进行分类监督，考虑建筑物的结构特征，UAV图像也可以提供可靠的代理，但是这些数据来源根本上还是进行野外调研产生的数据，所以需要找到更低成本的信息获取方式

对于SMD数据进行灾害损失程度的分类已经是存在的研究

光学图像和激光雷达图像融合的多模态数据用于语义分割已经是可能的

数据来源，首先是遥感图像可以通过global map获得，或者是网上的数据集，包含有多光谱的数据
然后就是洪水图像，需要搜索媒体数据，然后进行训练

![[Pasted image 20230422201609.png]]
这是构建脆弱度的工作流

接下来就是人工label这些建筑的脆弱程度，都是依据一些直觉性的依据然后寻找到对应的文献资料

需要进行图像预处理
这里是剪切和旋转

引入的自注意力模块是能够将语言和视觉多模态交互的作用，所以可以类比到遥感和街景图象的自注意力
但是文章是以街景图象作为主体进行评估而不是遥感图像，这一点和我们的研究有所区分
**这里使用的是自注意力模块去增强模型表现，我的想法是根据贝叶斯融合进行模型精度的增加，这个是可以进行比较的**

自注意力模块需要查一下是什么东西，什么原理实现的？
[自注意力模块（Self-attention block）是一种用于处理序列数据的神经网络结构，它能够比较序列中每个元素与其他元素之间的关系，并根据这些关系对每个元素进行加权求和，从而获得更丰富的上下文信息](https://towardsdatascience.com/an-intuitive-explanation-of-self-attention-4f72709638e1)[1](https://towardsdatascience.com/an-intuitive-explanation-of-self-attention-4f72709638e1)[。它是Transformer模型中的核心组成部分](https://zhuanlan.zhihu.com/p/410776234)[2](https://zhuanlan.zhihu.com/p/410776234)。
**就是transformer的主要结构**

还有sobel算子
[Sobel算子是一种常用于边缘检测的算子，它能够在粗精度下检测图像中的边缘信息。Sobel算子由两个3x3的卷积核构成，分别用于计算中心像素邻域的灰度加权差](https://blog.csdn.net/weixin_45399399/article/details/113811619)[1](https://blog.csdn.net/weixin_45399399/article/details/113811619)[。它通过离散微分方法求取图像边缘，并结合了高斯平滑滤波的思想，提高了对平缓区域边缘的响应](https://zhuanlan.zhihu.com/p/101261277)[2](https://zhuanlan.zhihu.com/p/101261277)。

本文采用的是10折交叉验证
使用的数据集是PASCAL SBD数据集和VOC 2012数据集的预训练模型，训练了150个epoch ，batch size是8（**要检查GPU可以运算的batch size是多大**）

文中采用的是网格划分，500m的网络计算每个网格的指数lv，得到不同区域的脆弱指数

最后还需要对于模型和其他的主流模型进行比较

整体表现在有2个级别的分类效果比较好，主要是卫星图像的精准度取决于太阳角度的问题

一般都采用的5分类级别，所以我们也进行5分类

实际情况下，选择冬季的街景图象可以减少影响，就是减少干扰的物体
