![[pdfviewer.pdf]]

根据您提供的页面内容，这篇文章的标题是“COMPARISON OF OBJECT DETECTION METHODS FOR CORN DAMAGE ASSESSMENT USING DEEP LEARNING”，发表在《Transactions of the ASABE》杂志上。文章的作者是A. Hamidisepehr, S. V. Mirnezami, J. K. Ward。

文章的摘要指出，严重的天气事件可能会给农民造成巨大的经济损失。关于损害地点和严重程度的详细信息将有助于农民、保险公司和灾难应对机构在灾后做出明智的决策。本研究的目标是通过使用计算机视觉和深度学习技术从航拍图像中检测受损玉米区域来证明概念。具体目标是比较现有的目标检测算法，以确定哪种最适合玉米损害检测。模拟玉米倒伏被用来创建训练和分析数据集。使用配备RGB相机的无人机进行图像采集。评估了三种流行的目标检测器（Faster R-CNN，YOLOv2和RetinaNet）对检测受损区域的能力。使用平均精度（AP）比较目标检测器。RetinaNet和YOLOv2在玉米损害识别方面表现出强大的能力，AP范围分别为98.43％至73.24％和97.0％至55.99％，涵盖所有条件。Faster R-CNN的表现不如其他两个模型，AP在77.29％至14.47％之间，适用于所有条件。对于所有三个目标检测器来说，在后期生长阶段检测玉米损害更加困难。

文章创新之处在于，它提出了一种新颖的方法来评估玉米损害情况。该方法利用计算机视觉和深度学习技术，通过比较现有的目标检测算法来确定哪种最适合玉米损害检测。实验结果表明，RetinaNet和YOLOv2在玉米损害识别方面表现出强大的能力。

2020年使用yolo进行玉米损失的研究，使用了retinanet的训练数据集和yolo的架构，表现比增强卷积要优秀
