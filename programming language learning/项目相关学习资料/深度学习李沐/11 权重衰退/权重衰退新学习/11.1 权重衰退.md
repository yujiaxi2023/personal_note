权重衰退是一种常见处理过拟合的方法
### 使用均方范数作为硬性限制

- 通过限制参数值的选择范围来控制模型容量
$$min\ l(w,b) \ subject \ to \ \|w\|^2\ \leq{\theta}$$

1. 通常不限制偏移b（没有多大区别）
2. 小的$\theta$ 意味着更强的正则项

小的$\theta$代表正则比较强，就是把数据规范到一定范围，最强的情况下就是w=0，如果w=1，w中每个值都不会超过1，随着w的元素增多，每个元素都会相对来说更少一些
这是一个硬性限制，这种优化相对来说比较麻烦

优化的是最小化的损失函数，最小化的时候加一个限制，让w的平方和小于一个特定值


### 使用均方范数作为柔性限制
- 对每个$\theta$ 都可以找到$\lambda$ 让之前的目标函数等价于下面
$$min \  l (w,b) + \frac{\lambda}{2}\|w\|^2$$
	- 可以通过拉格朗日乘子来证明
这就是限制项目挪掉之后的一个等价的内容
所以这里就把限制项替换成了一个penalty

- 超参数$\lambda$ 控制了正则项的重要程度
	- $\lambda = 0$ :无作用
	- $\lambda \ \to \ \infty , w^* \ \to  \ 0$ 
当λ趋向于∞的时候，θ等价于趋向0，这时候w也就趋向于0
如果希望模型不要太复杂，可以通过增加λ对模型复杂度进行限制，因为很多的w都变为0

##### 证明两个目标函数等价 拉格朗日乘子
首先，我们有两个优化问题：

1. $$\min \ l(w,b) + \frac{\lambda}{2}\|w\|^2$$
2. $$\min \ l(w,b) \quad \text{subject to} \quad \|w\|^2 \leq \theta$$

我们将第二个问题转换为带有约束的拉格朗日函数形式，引入拉格朗日乘子 \(\alpha\)：

定义拉格朗日函数为：
$$ \mathcal{L}(w, b, \alpha) = l(w, b) + \alpha \left(\|w\|^2 - \theta\right) $$

其中，$\alpha$ 是拉格朗日乘子，$\theta$ 是约束条件。

接下来，我们对拉格朗日函数分别对 $w$ 和 $b$ 求偏导并令其等于零，求解最优解：

$$\frac{\partial \mathcal{L}}{\partial w} = \frac{\partial l}{\partial w} + 2\alpha w = 0 \implies w = -\frac{1}{2\alpha} \frac{\partial l}{\partial w}$$

对 \(b\) 求偏导并令其等于零，得到：
$$\frac{\partial \mathcal{L}}{\partial b} = \frac{\partial l}{\partial b} = 0$$

接下来，将 $w$ 的解带入拉格朗日函数中：

$$\mathcal{L}(w, b, \alpha) = l\left(-\frac{1}{2\alpha} \frac{\partial l}{\partial w}, b\right) + \alpha \left(\left\|-\frac{1}{2\alpha} \frac{\partial l}{\partial w}\right\|^2 - \theta\right)$$

最小化该拉格朗日函数，令其对 $\alpha$ 求导数为零：

$$\frac{\partial \mathcal{L}}{\partial \alpha} = \left\|-\frac{1}{2\alpha} \frac{\partial l}{\partial w}\right\|^2 - \theta = 0$$

整理得到：
$$\left\|-\frac{1}{2\alpha} \frac{\partial l}{\partial w}\right\|^2 = \theta \implies \left\|\frac{\partial l}{\partial w}\right\|^2 = 4\alpha^2 \theta$$

从中解出拉格朗日乘子 $\alpha$：
$$\alpha = \sqrt{\frac{1}{4\theta}\left\|\frac{\partial l}{\partial w}\right\|^2}$$

将其带入拉格朗日函数，得到最终形式：
$$l\left(-\frac{1}{2\alpha} \frac{\partial l}{\partial w}, b\right) + \alpha \left(\left\|-\frac{1}{2\alpha} \frac{\partial l}{\partial w}\right\|^2 - \theta\right) = l(w, b) + \frac{\lambda}{2}\|w\|^2$$

因此，通过引入拉格朗日乘子 $\alpha$ 并求解其最优解，我们证明了两个目标函数是等价的。


### 演示对最优解的影响
$$w^* = argmin \ l(w,b) \ + \frac{\lambda}{x}\|w\|^2$$
$$\tilde{w}^* \ = argmin l(w,b)$$

假设函数是 $l$ ，这里l的最优解是下面的$\tilde{w}^*$
假设我是优化$l$

绿线就是$l$的等高线，添加的罚也是二次函数，可以看作一个原点为中心的等高线，当$\tilde{w}^*$向$w^*$ 靠近的时候，罚变小，损失函数变大一点
损失函数在优化点附近的时候变化比较小，对于罚的优化会更多
![[Pasted image 20231227213021.png]]
![[Pasted image 20231227213035.png]]
罚的引入让最优解向原点移动了
w的绝对值变小，模型复杂度就会变低
小的参数代表这个特征或者信息是不敏感的，减少这些不必要信息的拟合


### 参数更新法则
- 计算梯度
$$
\frac{\sigma}{\sigma w}(l(w,b)+\frac{\lambda}{2}\|w\|^2)=\frac{\sigma l(w,b)}{\sigma w}+\lambda w
$$ 

- 时间更新参数
$$
w_{t+1} = (1-\eta \lambda)w_t - \eta \frac{\sigma l(w_t, b_t)}{\sigma w_t}
$$

- 通常$\eta \lambda \textless 1$ ，在深度学习中叫做权重衰退

等于是先将前一个权重乘以小于1的数，缩小之后再进行梯度下降

### 总结

- 权重衰退通过L2正则项让模型参数不会过大，从而控制模型复杂度
- 正则项权重是控制模型复杂度的超参数

