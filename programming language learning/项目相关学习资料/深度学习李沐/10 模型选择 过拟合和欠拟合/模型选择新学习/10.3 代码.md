使用下面的三阶多项式来生成训练和测试数据的标签
$$ y = 5 + 1.2x -3.4\frac{x^2}{2!} + 5.6\frac{x^3}{3!} + \epsilon \text{where} \epsilon \sim \mathcal{N}(0, 0.1^2).$$

真实的label是y，这里2！和3！是为了让这一项不要太大，然后加上一些噪音
实际生成生成一个特征是20的东西
首先看看数据集什么样子
```python
import math  
import numpy as np  
import torch  
from torch import nn  
from d2l import torch as d2l  
  
max_degree = 20  
n_train, n_test = 100, 100  
true_w = np.zeros(max_degree)  
true_w[0:4] = np.array([5, 1.2, -3.4, 5.6])  
  
features = np.random.normal(size=(n_train + n_test, 1))  
np.random.shuffle(features)  
poly_features = np.power(features, np.arange(max_degree).reshape(1, -1))  
for i in range(max_degree):  
    poly_features[:,i] /= math.gamma(i + 1)  
labels = np.dot(poly_features, true_w)  
labels += np.random.normal(scale=0.1, size=labels.shape)  
  
true_w, features, poly_features, labels = [  
    torch.tensor(x, dtype=torch.float) for x in [true_w, features, poly_features, labels]  
]  
  
# 数据集长什么样子  
print(features[:2], poly_features[:2, :], labels[:2])
```

然后实现一个损失的评估
```python
def evaluate_loss(net, data_iter, loss):  
    """  
    评估给定数据集上模型的损失  
    """    metric = d2l.Accumulator(2)  
    for X, y in data_iter:  
        out = net(X)  
        y = y.reshape(out.shape)  
        l = loss(out, y)  
        metric.add(l.sum(), l.numel())  
    return metric[0] / metric[1]
```

然后实现一个训练函数，简单的
```python
def train(train_features, test_features, train_labels, test_labels, num_epochs=400)  
    loss = nn.MSELoss()  
    input_shape = train_features.shape[-1]  
    net = nn.Sequential(nn.Linear(input_shape, 1, bias=False))  
    batch_size = min(10, train_labels.shape[0])  
    train_iter = d2l.load_array((train_features, train_labels.reshape(-1, 1)), batch_size)  
    test_iter = d2l.load_array((test_features, test_labels.reshape(-1,1)), batch_size, is_train=False)  
    trainer = torch.optim.SGD(net.parameters(), lr=0.01)  
    animater = d2l.Animator(xlabel='epoch', ylabel='loss', yscale='log',  
                            xlim=[1, num_epochs], ylim=[1e-3, 1e2],  
                            legend=['train', 'test'])  
    for epoch in range(num_epochs):  
        d2l.train_epoch_ch3(net, train_iter, loss, trainer)  
        if epoch == 0 or (epoch + 1) % 20 == 0:  
            animater.add(epoch + 1, (evaluate_loss(net, train_iter, loss),  
                                     evaluate_loss(net, test_iter, loss)))  
  
    print("weight:", net[0].weight.data.numpy())
```
我们的函数只有前四列有权重，后边的是噪音
```python
train(poly_features[:n_train, :4], poly_features[n_train:, :4],  
      labels[:n_train], labels[n_train:])  
d2l.plt.show()
```
我们给全了数据进行训练
![[Pasted image 20231225200938.png]]
```python
train(poly_features[:n_train, :2], poly_features[n_train:, :2],  
      labels[:n_train], labels[n_train:])  
d2l.plt.show()
```
只给了前两列进行训练
![[Pasted image 20231225201014.png]]
这就是欠拟合，数据没有给全

```python
train(poly_features[:n_train, :], poly_features[n_train:, :],  
      labels[:n_train], labels[n_train:], num_epochs=1500)  
d2l.plt.show()
```
![[Pasted image 20231225201153.png]]
这三张图看不太出来就是了


## 小结

* 欠拟合是指模型无法继续减少训练误差。过拟合是指训练误差远小于验证误差。
* 由于不能基于训练误差来估计泛化误差，因此简单地最小化训练误差并不一定意味着泛化误差的减小。机器学习模型需要注意防止过拟合，即防止泛化误差过大。
* 验证集可以用于模型选择，但不能过于随意地使用它。
* 我们应该选择一个复杂度适当的模型，避免使用数量不足的训练样本。


## 练习

1. 这个多项式回归问题可以准确地解出吗？提示：使用线性代数。
$$ y = 5 + 1.2x -3.4\frac{x^2}{2!} + 5.6\frac{x^3}{3!} + \epsilon \text{where} \epsilon \sim \mathcal{N}(0, 0.1^2).$$

2. 考虑多项式的模型选择。
    1. 绘制训练损失与模型复杂度（多项式的阶数）的关系图。观察到了什么？需要多少阶的多项式才能将训练损失减少到0?
    2. 在这种情况下绘制测试的损失图。
    3. 生成同样的图，作为数据量的函数。

3. 如果不对多项式特征$x^i$进行标准化($1/i!$)，会发生什么事情？能用其他方法解决这个问题吗？

4. 泛化误差可能为零吗？

1. 对于给定的多项式回归问题，可以使用线性代数的方法求解。首先，将问题表示为矩阵形式 $Xw = y$，其中 $X$ 是包含输入特征的矩阵，$w$ 是待求解的权重向量，$y$ 是输出向量。然后，通过求解线性方程组 $Xw = y$ 来找到权重向量 $w$。在这个问题中，$X$ 的列将包含 $x^0, x^1, x^2, x^3$ 等。
    
2. 1. 绘制训练损失与模型复杂度（多项式的阶数）的关系图时，通常会观察到训练损失随着模型复杂度的增加而减小，但过高的复杂度可能导致过拟合。需要通过交叉验证等方法找到一个适当的模型复杂度。
    2. 在测试损失图中，观察测试损失是否随着模型复杂度的增加而增大，这可能是过拟合的迹象。
    3. 数据量的增加可能导致过拟合问题减轻，因此需要生成同样的图，观察模型在不同数据量下的性能。
3. 如果不对多项式特征 $x^i$ 进行标准化，可能会导致高阶特征对模型的影响过大，使得优化过程变得困难。标准化可以确保各特征的尺度相近，有助于优化算法更快地收敛。可以尝试其他方法，如正则化，以缓解这个问题。
    
4. 泛化误差可能不会为零。即使在训练损失为零的情况下，模型也可能对新数据表现不佳，这是因为模型过度适应了训练数据（过拟合）。为了评估泛化误差，建议使用验证集或交叉验证，以更好地了解模型在未见过的数据上的性能。