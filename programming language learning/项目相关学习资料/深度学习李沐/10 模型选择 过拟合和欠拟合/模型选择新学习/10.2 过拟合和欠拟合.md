underfitting和overfitting

![[Pasted image 20231123150218.png]]
数据和模型需要对等
简单数据对应简单模型
复杂数据对应复杂模型

比如MLP就比线性模型容量更大

所以如何判断数据是否是复杂是选择模型的关键

## 模型容量

- 拟合各种函数的能力
- 低容量的模型难以拟合训练数据
- 高容量的模型可以记住所有的数据
![[Pasted image 20231123150513.png]]

两种情况并不好
比较好的情况是
![[Pasted image 20231123150621.png]]

**我们的核心任务是把泛化误差减小**
![[Pasted image 20231123151013.png]]
- 深度学习的核心其实是要承受一定的过拟合，也就是模型容量首先要足够大，然后通过手段控制模型容量减少泛化误差
- 所以过拟合并不是一件坏事

## 估计模型容量

- 难以在不同种类算法之间比较
	- 例如树模型和神经网络
- 给定一个模型种类，将有两个主要因素
	- 参数的个数
	- 参数值的选择范围
![[Pasted image 20231123151233.png]]
明显右边模型参数量更大
如果参数值可以在很大范围内选择，那模型容量就高

**我们通过调整这两个属性，控制模型容量**

## VC dimension

- 统计学习理论的核心思想
- 对于一个分类模型，VC等于一个最大的数据集的大小，不管如何给定标号，都存在一个模型来对他进行完美分类

### 线性分类器的VC维

- 2维输入的感知机，VC维=3
	- 能够分类任意三个点，但是不能4个（xor）
- 支持N维输入的感知机的VC维是N+1
- 一些多层感知机的VC维$O(N\log_2{N})$ 
![[Pasted image 20231123151700.png]]

### VC维的用处

- 提供为什么一个模型好的理论依据
	- 它可以衡量训练误差和泛化误差之间的间隔
- 但是深度学习中很少使用
	- 衡量不是很准确
	- 计算深度学习模型的VC维度很复杂

## 数据复杂度

- 多个重要因素
	- 样本个数
	- 每个样本的元素个数
	- 时间空间结构
	- 多样性

## 总结

- 模型容量需要匹配数据复杂度，否则导致欠拟合过拟合
- 统计机器学习提供数学工具衡量模型复杂度
- 实际中按照观察训练误差和验证误差来判断

## 模型选择，欠拟合和过拟合

机器学习科学家的目标是发现模式（pattern），但是我们得确信模型发现的是一种泛化的模式而不是简单的记住了数据

我们往往会碰到一种问题就是，我们用来训练的样本数量相对于我们需要应用的对象来说太小了，比如我们要预测天气的影响因素，那我们记录下来的用于训练的天气数据可能只有数十万小时的记录，这对于漫长的气候变化过程来说是显然不够的，我们的模型就很容易陷入，一旦获得了新的数据，就会把原来发现的规律给推翻。

将模型在训练数据上拟合的比在潜在分布中更接近的现象称之为overfitting，用于对抗过拟合的技术称为正则化regularization。


## 统计学习理论
由于泛化是机器学习中的基本问题， 许多数学家和理论家毕生致力于研究描述这一现象的形式理论。 在[同名定理（eponymous theorem）](https://en.wikipedia.org/wiki/Glivenko%E2%80%93Cantelli_theorem)中， 格里文科和坎特利推导出了训练误差收敛到泛化误差的速率。 在一系列开创性的论文中， [Vapnik和Chervonenkis](https://en.wikipedia.org/wiki/Vapnik%E2%80%93Chervonenkis_theory) 将这一理论扩展到更一般种类的函数。 这项工作为统计学习理论奠定了基础。

假设训练数据和测试数据都是从相同的分布中独立提取的。通常称为独立同分布假设（i.i.d. assumption），这意味着对数据采样的过程没有进行记忆，换句话说，抽取的第2个样本和第3个样本的相关性，并不比抽取第2个样本和第200万个样本的相关性更强。

但是实际上，很多问题都是违反独立同分布的假设的，这主要体现在训练数据的时间依赖性和空间依赖性上，但是有的时候这并不影响模型的运行。
所以泛化性能是一个很难说清楚的事情。

### 模型复杂性

当我们有简单的模型和大量的数据的时候，我们期望泛化误差和训练误差是相近。当我们有**更复杂的模型和更少的样本**一般我们预计训练误差会下降，但是泛化误差会增大。


本节为了给出一些直观的印象，我们将重点介绍几个倾向于影响模型泛化的因素。

1. 可调整参数的数量。当可调整参数的数量（有时称为_自由度_）很大时，模型往往更容易过拟合。
2. 参数采用的值。当权重的取值范围较大时，模型可能更容易过拟合。
3. 训练样本的数量。即使模型很简单，也很容易过拟合只包含一两个样本的数据集。而过拟合一个有数百万个样本的数据集则需要一个极其灵活的模型


## 模型选择

在机器学习中，我们通常在评估几个候选模型后选择最终的模型。 这个过程叫做_模型选择_。 有时，需要进行比较的模型在本质上是完全不同的（比如，决策树与线性模型）。 又有时，我们需要比较不同的超参数设置下的同一类模型。

例如，训练多层感知机模型时，我们可能希望比较具有 不同数量的隐藏层、不同数量的隐藏单元以及不同的激活函数组合的模型。 为了确定候选模型中的最佳模型，我们通常会使用验证集。

### 验证数据集

原则上，在我们确定所有的超参数之前，我们不希望用到测试集。 如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险，那就麻烦大了。 如果我们过拟合了训练数据，还可以在测试数据上的评估来判断过拟合。 但是如果我们过拟合了测试数据，我们又该怎么知道呢？

因此，我们决不能依靠测试数据进行模型选择。 然而，我们也不能仅仅依靠训练数据来选择模型，因为我们无法估计训练数据的泛化误差。

在实际应用中，情况变得更加复杂。 虽然理想情况下我们只会使用测试数据一次， 以评估最好的模型或比较一些模型效果，但现实是测试数据很少在使用一次后被丢弃。 我们很少能有充足的数据来对每一轮实验采用全新测试集。

解决此问题的常见做法是将我们的数据分成三份， 除了训练和测试数据集之外，还增加一个_验证数据集_（validation dataset）， 也叫_验证集_（validation set）。 但现实是验证数据和测试数据之间的边界模糊得令人担忧。 除非另有明确说明，否则在这本书的实验中， 我们实际上是在使用应该被正确地称为训练数据和验证数据的数据集， 并没有真正的测试数据集。 因此，书中每次实验报告的准确度都是验证集准确度，而不是测试集准确度。

### $K$折交叉验证

当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集。
这个问题的一个流行的解决方案是采用$K$*折交叉验证*。
这里，原始训练数据被分成$K$个不重叠的子集。
然后执行$K$次模型训练和验证，每次在$K-1$个子集上进行训练，
并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。
最后，通过对$K$次实验的结果取平均来估计训练和验证误差。


### 欠拟合还是过拟合

当我们比较训练和验证误差时，我们要注意两种常见的情况。 首先，我们要注意这样的情况：训练误差和验证误差都很严重， 但它们之间仅有一点差距。 如果模型不能降低训练误差，这可能意味着模型过于简单（即表达能力不足）， 无法捕获试图学习的模式。 此外，由于我们的训练和验证误差之间的_泛化误差_很小， 我们有理由相信可以用一个更复杂的模型降低训练误差。 这种现象被称为_欠拟合_（underfitting）。

另一方面，当我们的训练误差明显低于验证误差时要小心， 这表明严重的_过拟合_（overfitting）。 注意，_过拟合_并不总是一件坏事。 特别是在深度学习领域，众所周知， 最好的预测模型在训练数据上的表现往往比在保留（验证）数据上好得多。 最终，我们通常更关心验证误差，而不是训练误差和验证误差之间的差距。

### 模型复杂性

为了说明一些关于过拟合和模型复杂性的经典直觉，
我们给出一个多项式的例子。
给定由单个特征$x$和对应实数标签$y$组成的训练数据，
我们试图找到下面的$d$阶多项式来估计标签$y$。

$$\hat{y}= \sum_{i=0}^d x^i w_i$$

这只是一个线性回归问题，我们的特征是$x$的幂给出的，
模型的权重是$w_i$给出的，偏置是$w_0$给出的
（因为对于所有的$x$都有$x^0 = 1$）。
由于这只是一个线性回归问题，我们可以使用平方误差作为我们的损失函数。

高阶多项式函数比低阶多项式函数复杂得多。
高阶多项式的参数较多，模型函数的选择范围较广。
因此在固定训练数据集的情况下，
高阶多项式函数相对于低阶多项式的训练误差应该始终更低（最坏也是相等）。
事实上，当数据样本包含了$x$的不同值时，
函数阶数等于数据样本数量的多项式函数可以完美拟合训练集。

### 数据集大小

另一个重要因素是数据集的大小。 训练数据集中的样本越少，我们就越有可能（且更严重地）过拟合。 随着训练数据量的增加，泛化误差通常会减小。 此外，一般来说，更多的数据不会有什么坏处。 对于固定的任务和数据分布，模型复杂性和数据集大小之间通常存在关系。 给出更多的数据，我们可能会尝试拟合一个更复杂的模型。 能够拟合更复杂的模型可能是有益的。 如果没有足够的数据，简单的模型可能更有用。 对于许多任务，深度学习只有在有数千个训练样本时才优于线性模型。 从一定程度上来说，深度学习目前的生机要归功于 廉价存储、互联设备以及数字化经济带来的海量数据集。


