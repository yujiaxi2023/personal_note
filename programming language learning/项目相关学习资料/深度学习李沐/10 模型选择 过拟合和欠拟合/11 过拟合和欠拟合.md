under fitting over fitting

![[Pasted image 20230928142334.png]]
根据数据的复杂程度选择模型容量
如果数据简单就使用低的模型容量，选择更浅的神经网络
如果数据复杂就使用高的模型容量，选择更深的神经网络

# 模型容量

- 拟合各种函数的能力
- 低容量的模型难以拟合训练数据
- 高容量的模型可以记住所有的训练数据

![[Pasted image 20230928142701.png]]

容易拟合噪音，高容量模型

# 模型容量的影响

![[Pasted image 20230928142737.png]]

所以我们会一开始选择一个大的模型，然后选择一个降低模型容量

# 估计模型容量

- 难以在不同种类算法之间比较
	- 例如树模型和神经网络
- 给定一个模型种类，将有两个主要因素
	- 参数的个数
	- 参数值的选择范围

![[Pasted image 20230928144027.png]]

# VC维

-  统计学习理论的一个核心思想
-  对于一个分类模型，VC等于一个最大的数据集的大小，不管如何给定标号，都存在一个模型对他进行完美分类

# 显性分类器的VC维

- 2维输入的感知机，VC维=3
	- 能够分类任何3个点，但不是4个（xor）
![[Pasted image 20230928162221.png]]
- 支持N维输入的感知机的VC维度是N+1
- 一些多层感知机的VC维是O（Nlog2N）


# VC维的用处

- 提供为什么一个模型好的理论依据
	- 它可以衡量训练误差和泛化误差之间的间隔
- 但深度学习很少用
	- 衡量不是很准确
	- 计算深度学习模型的VC维很困难

# 数据复杂度

- 多个重要因素
	- 样本个数
	- 每个样本元素个数
	- 时间，空间结构
	- 多样性

# 总结

- 模型容量需要匹配数据复杂度，不然会欠拟合或者过拟合
- 统计机器学习提供数学工具衡量模型复杂度
- 实际中一般观察训练误差和验证误差


**问题1：svm的缺点是通过一个kernel来匹配模型复杂度，很难做到100万个数据链，十万个点以下可以做到，但是以上就难以做到，svm可以调整的东西不多
问题2：神经网络的优点在于是一个语言系统，可以来描述人的理解
问题3：模型剪枝和蒸馏是针对部署的操作
问题4：validation dataset是代表未经训练的数据集，在很多研究中都是使用test dataset来代替validation
问题5：如果是时间序列的数据，训练集和验证集有自相关，这时候需要的是验证集一定是后发生的数据
问题6：验证数据集和训练数据集的数据清理（异常值处理）和特征构建（标准化）？最简单的方式是标准化减去平均值除以方差，所有的一起做，第二种方式是只使用训练数据集的均值和方差，在验证数据集中使用，但是前者可以增加鲁棒性
问题7：K折交叉验证一般使用在数据集不够的情况下使用，因为成本太高
问题8：cross validation是解决超参数的选择问题而不是解决训练数据集和验证数据集的特征是否相似的问题
问题9：模型参数是w和b，超参数是选择线性模型还是多层感知机，学习率多少，每层是多大，有多少层？
问题10：cross validation选择的是平均精度，不是某一次的结果
问题11：设计超参数怎么设计，网格，随机，贝叶斯推理等，超参数的设计只有通过经验设计，随机方法或者贝叶斯都需要大量的训练才能自动的出来一个较好的超参数，HPO的问题
问题12：不平衡数据集在验证数据集的时候采用平衡数据集
问题13：k折交叉验证的目的？k折就是确定一个超参数，然后再全数据中进行训练，或者不进行训练，随便找一个精度最好的一折模型就行，这样可以增加模型的稳定性robust
问题14：训练误差是否是模型容量越大就一直下降
![[Pasted image 20230928171550.png]]
这里是表示多个模型，代表更深层的CNN或者更深层的MLP
问题15：常见做法是随机森林，svm，神经网络都做一遍，然后做avg
问题16：做K折很容易得出更好的表现，也有使用多次随机初始化之后做avg也可以
问题17：VC维代表一个模型能够记住最大的数据集是什么样的
问题18：K折交叉验证一般是最开始进行K分类，也有随机打乱数据，获得n分之一进行训练验证，然后求avg
问题19：神经网络是语言用来描述对于这个问题的理解，比如CNN就是对于空间的理解，RNN是对于时序信息的理解，实际上work的理由跟最开始设计的时候设定的目标是不同的
问题20：蒸馏模型是跟另外一个小模型比可能是更好性能，但是跟原始的模型可能不好的性能，多个模型集合是为了降低方差，有更好的robust
问题21：如果样本不平衡，需要加权使他平衡，而且要考虑现实世界的一个标准，如果世界上就是90比10的比率发生问题，那就直接训练，如果是数据收集问题，那就是需要调整权重