主进程代码结束后,主进程可能没有结束, 因为需要等待子进程运行结束后执行回收进程回收当前的进程资源

主进程如何在数据隔离的情况下知道每一个子进程甚么时候结束?
子进程完全可能存在input,recv这种阻塞性代码, 所以**主进程不可能判断每一个子进程如何结束**, 但是可以让子进程结束的时候发出一个信号告诉父进程结束了. 父进程接收到子进程的结束信号就会回收子进程的资源
这个发送和接受信号的过程,就是进程间通信(IPC)

### 进程间的通信

了解进程间的通信,首先需要搞清楚,主进程和子进程的关系

#### 进程的关系

linux系统中,无论使用os.fork或者multiprocessing.Process()创建进程,都是通过操作系统创建进程, 这个时候我们可以看作是fork所在的进程就是父进程parent process,相对应的fork创建出来的就是子进程

但是操作系统中实际上(无论什么操作系统), 子进程都是基于复制父进程创建的副本, 所以子进程和父进程实际上, 在内存中都拥有独立的空间, 操作系统中看来就类似于兄弟的关系. 这点在linux下面非常明显.
linux下面父进程和子进程的代码段是共享,数据段是隔离的,子进程的数据段空间完全就是父进程的复制, 甚至于指令指针也是完全相同, 子进程拥有父进程当前运行的代码位置, 所以之前的学习中, 我们说os.fork后边的代码就是子进程要执行的代码. 原因就是父进程在创建子进程之前, 就已经运行了os.fork之前的代码了,而父进程运行的代码位置状态信息就存放在数据段中

创建了子进程后代码还是继续往下运行,因为python语言的的特性
所以这就是位置状态信息的记录
![[Pasted image 20240206195914.png]]

#### 进程间的数据隔离

```python
import time, random  
from multiprocessing import Process  
  
num = 100  
  
def func():  
    global num  
    num -= 1  
  
if __name__ == "__main__":  
    process_list = []  
  
    for i in range(10):  
        p = Process(target=func)  
        p.start()  
        process_list.append(p)  
  
    for p in process_list:  
        p.join()  
  
    print(num) # num=?
```
这个num的结果是100
这就是因为数据隔离
主进程中的数据集会完整的复制到子进程中,而子进程处理自己的数据集
![[Pasted image 20240206200838.png]]

如果要进行通信,有两种方式:
1. 基于网络(AF_INET)
2. 基于文件(AF_UNIX)

进程间通信,其实没有基于网络,需要网络资源而调用网络IO也会产生延时,所以开发中针对进程的通信时不需要网络, 一般采用文件进行通信

#### 进程间的通信-IPC
IPC(Inter-Process Communication)进程间的通信,multipreocessing模块支持进程间通信的两种主要队列形式, **队列(Queue)** 和管道(Pipe), 管道并不常用,但是管道是基于队列实现的

Queue
是一个介于文件(AF+UNIX)实现的socket通信队列模块,通信过程中采用的pickle压缩传输,额可以让我们使用IPC通信,不仅具有队列的先进先出后进后出的特点,还内置实现了Lock机制

常用方法

| 方法名 | 描述 |
| ---- | ---- |
| q.get([block[, timeout]]) | 返回队列q中的一个数据项.<br>如果队列q为空, 此方法将阻塞程序,知道队列中有数据项为止. <br>block被用于控制阻塞行为,默认为True<br>如果设置为False,将引发Queue.Empty异常<br>timeout是可选超时时间,用在阻塞模式中<br>如果在指定的时间间隔内没有项目变为可用,将引发Queue.Empty异常 |
| q.put(item[,block[, timeout]]) | 将item放入队列<br>如果队列已满,此方法将阻塞到有用空间位置<br>block控制阻塞行为,默认为True<br>如果设置为false,将引发Queue.Empty异常<br>timeout指定在阻塞模式中等待可用空间的时间长短<br>超时后将引发Queue.Full异常 |
上面是读取队列中的数据项
下面是放入数据项

基本用法

```python
from multiprocessing import Queue  
  
# 创建一个队列  
# q = Queue() # 不设置队列的长度  
q = Queue(2) # 设定长度的队列  
print(q)  
  
# 添加数据到队列中  
q.put(1)  
q.put(2)  
# q.put(3) # 对于定长的队列，如果队列满了，再次使用put会进入阻塞状态  
print(q.qsize()) # 查看队列中数据项数量 2  
# 从队列中提取数据  
print(q.get()) # 输出是1，因为是先进先出  
print(q.get()) # 2  
# 全部拿完了之后数据项数量是0  
print(q.qsize()) # 0  
# 如果继续使用q.get，就会进入阻塞，这就是对队列提取数据  
# q.get()   
# 直到另一个进程添加数据项到队列中，不然就会阻塞，一直到报error  
# 同理对于添加数据到定长队列，也是一样
```

队列实现IPC通信

```python
from multiprocessing import Queue, Process  
  
def func(exp, q):  
    # 把传递进来的exp字符串当作python代码运行，将结果返回主进程  
    ret = eval(exp) # eval就是执行字符串代码，里面只能放表达式  
    # eval + exec  
    print(ret)  
    # 把结果保存到队列中  
    q.put(ret)  
  
if __name__ == "__main__":  
    q = Queue()  
    # 把队列对象作为参数传递到需要通信的子进程中  
    p = Process(target=func, args=("10+20+30", q)).start()  
    # 从队列中提取数据  
    print(q.get())
```
这样就可以将子进程的数据传递给父进程了
这里Process创建了子进程,子进程中定义了ret变量,然后放到了q之中
然后q是一个队列,所以子进程的数据就可以传递给父进程了
这是建立在父进程和子进程的数据集相互独立的情况下

其实使用queue是创建了一个socket文件

**Pipe**

Pipe是一个基于文件(AF_UNIX)类型实现的socket通信管道对象,通信过程中的数据采用pickle压缩传递,可以使用IPC通信,但是并不Queue通信队列的先进先出和Lock特点,所以并不安全,很少使用

pipe实现IPC通信,代码
```python
from multiprocessing import Process, Queue, Pipe  
  
def func(exp, con1):  
    ret = eval(exp)  
    print(ret)  
    con1.send(ret)  
  
if __name__ == "__main__":  
    # 创建一个管道，返回值是一个元组，对应的就是管道的输入输出端，两个方向  
    con1, con2 = Pipe()  
    p = Process(target=func, args=("10+20+30", con1)).start()  
    # 接受来自管道的另一端发送的数据  
    print(con2.recv())
```
在multiprocessing中的队列和管道的关系
队列是包含管道和lock的
管道其实是基于socket来实现的, 里面传递数据用pickle格式
![[Pasted image 20240206205409.png]]
