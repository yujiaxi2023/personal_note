多线程导致数据并发的问题
```python
from threading import Thread  
  
data = {"count":5}  
  
def buy_ticket(username):  
    """购买车票"""  
    global data  
    if data["count"] > 0:  
        print(f"{username}成功购买车票")  
        data["count"] -= 1  
  
if __name__ == '__main__':  
    for i in range(10):  
        p = Thread(target=buy_ticket, args=(f'user-{i}', ))  
        p.start()
```
上面代码中，没有数据不一致的问题，因为python解释器给执行的所有线程加了一个全局共享的锁，这把锁叫做GIL锁。

### 全局解释器

GIL（global interpreter lock）叫做全局解释器锁，是Cpython解释器中提供的一个全局锁（并不是python语法），每个线程在执行的时候都需要先获得GIL锁，保证了python解释器在运行多个线程的时候，同一时间一个线程只能被一个cpu执行
除了Cpython之外还有pypy Jpython Irionpython（.NET语言），
只有Cpython是如此
因为在多核CPU多线程操作系统中，GIL也会限制CPU在同一时间内只执行一个线程，因此GIL锁成为了Cpython解释器的一个不好的特性
GIL是因为GC垃圾回收机制的引用计数器设计的，早在操作系统没有线程的概念的时候，Python的GIL就已经存在，后边改不动了

本质上GIL就是一个布尔值
如果多进程的时候使用不同CPU执行不同线程下创建的变量，例如创建了两个a变量，同时创建会导致a的引用计数器变为2

全局解释器锁也会带来一个数据一致性的问题
只要在线程数量过大的时候发生，也就是大批量密集型的计算操作，也就是计算密集型错误，这是因为时间片轮调度算法和GIL全局解释器之间的冲突问题

```python 
from threading import Thread  
  
num = 0  
  
def func():  
    global num  
    # 大批量执行计算操作，一般叫做计算密集型任务  
    for i in range(2000000):  
        num += 1  
  
  
if __name__ == '__main__':  
    thread_list = []  
    for i in range(10):  
        t = Thread(target=func)  
        t.start()  
        thread_list.append(t)  
  
    for t in thread_list:  
        t.join()  
  
    print(num) # 9175179
```

时间片因为是0.1秒（假如，可以是一个很短的时间）去执行一个程序，然后这个时间是不够我们程序执行200万次操作的，所以这个时候会跳到别的程序去执行，这里执行的每次+1都可能丢失一个1，所以得出的结果就可能更小

开发的程序一般可以分为两种：计算密集型和IO密集型

计算密集型任务的特点是需要大量的计算消耗CPU资源，视频解码，计算无理数等，这种任务应该减少GIL对程序的影响，所以采用多进程或者别的解释器

IO密集型的，例如网络数据手法，大文件读写，这种任务需要大量时间等待IO操作完成，会导致CPU空闲，由于GIL存在，同一时刻只有一个线程执行所以GIL锁对于IO密集型任务影响很小，多线程适合IO密集型任务，例如网络爬虫，web服务器/框架这种

Lock和GIL不一样的点是在：
1. Lock和GIL，Lock是针对单个进程添加，GIL是默认CPython解释器中添加，GIL针对是所有进程下的所有线程
2. Lock和GIL都是互斥锁。GIL是Cpython解释器管理，所以没有死锁现象，Lock因为是自己管理，就会出现死锁现象