图片的表示方法feature map
例如一个手写数字8的图片
![[Pasted image 20230510114101.png]]
在计算机视觉中就是
![[Pasted image 20230510114124.png]]
这样的数据
可以用一个矩阵表示
数据存储的时候是0-255的范围

计算机视觉使用的RGB图片
忽略alpha 通道的话可以看作RGB三通道的图片
![[Pasted image 20230510114314.png]]
![[Pasted image 20230510114322.png]]
对应的矩阵如上图
一般会对数据进行归一化处理

虽然可以分开看三个通道 但是在卷积神经网络中是三个通道叠加在一起看到
![[Pasted image 20230510114439.png]]
![[Pasted image 20230510114448.png]]
对于这种具有位置相关的数据
神经网络是如何输入的

对于神经网络第一层是输入层 但是在计算神经网络深度的时候不计算这一层
下图是一个4层的包含3个隐藏层的全连接神经网络的架构
![[Pasted image 20230510114640.png]]
一层的概念是包含权值和输出
![[Pasted image 20230510114719.png]]
如果使用的MNIST手写数字数据集识别数字
采用全连接层将28x28的数据flatten为784维的向量

上面的网络中有几条线就是有几个参数
可以得出有390k个参数
每个参数如果是浮点型就是4字节储存一个参数
所以占用的内存有1.6m非常大
![[Pasted image 20230510115119.png]]
所以使用全连接层无疑是一个不合理的结构，对于当时的计算机来说
所以引用了感受野 和卷积神经网络
![[Pasted image 20230510115336.png]]
感受野是权值共享的
这样利用一个局部相关性的理念，让同一区域的内容使用同样的权值
这样产生的神经网络可以大大减少消耗的内存量
![[Pasted image 20230510115654.png]]
使用感受野例如3x3的感受野对图片的3x3区域进行运算点积得出一个数
就是形成的feature map
![[Pasted image 20230510115935.png]]
为什么叫卷积神经网络呢
就是因为有一个卷积的定义
为图中的函数
例如有一个矩形 在矩形的外侧有一个一样的矩形
然后沿着x轴移动之后会有一段距离之后形成重叠
重叠到最大就是到达顶点
然后再减小
这就是卷积运算

![[Pasted image 20230510120313.png]]
这里就显示了输出的feature map的形状x 和 y就是kernel 在input中的移动距离
卷积运算时从左往右从上到下
![[Pasted image 20230510120519.png]]
![[Pasted image 20230510120530.png]]
![[Pasted image 20230510120544.png]]
卷积可以在边缘检测 模糊等
使用不同的kernel得到不同的特征feature map
