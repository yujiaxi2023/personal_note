使用交叉熵函数
![[Pasted image 20230707211830.png]]
使用一个10层输出的10分类问题

![[Pasted image 20230707212630.png]]
没有经过sigmoid和softmax是logits，logits就是未进行归一化的预测向量
这里使用relu也是可以的，但是最原始是不需要的

训练过程中需要定义一个优化器
这里使用的cross entropy loss 跟F.entropy一样的
它其实是一个包包含softmax log 加 nnloss的操作
得到的logits不能添加softmax
softmax会将数值缩小到1以内
然后调用loss 的 cross entropy函数
![[Pasted image 20230707222045.png]]

这样train的网络得到的loss在后边不变了，说明梯度信息弥散了
因为需要初始化
这里使用了kaiming初始化这样结果就会变得更好了
![[Pasted image 20230707223016.png]]
