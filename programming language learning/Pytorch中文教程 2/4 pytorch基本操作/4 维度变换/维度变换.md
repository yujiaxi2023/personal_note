常用的维度变化
类似于numpy中的reshape函数

- view/reshape
- squeeze/unsqueeze
- transpose/t/permute
- expand/repeat

**view/reshape**
pytorch0.3之前使用的view 后来为了与numpy一致就添加了reshape函数
使用任何一个功能都是一样的

```python
a = torch.rand(4,1,28,28)

a.shape
a.view(4,28*28)

a.view(4,28*28).shape
a.view(4*28,28).shape
a.view(4*1, 28, 28).shape
b = a.view(4,784)
b.view(4, 28,28,1)
```
我们进行维度变换需要满足物理意义
不然会破坏数据,污染数据库
而且保证reshape后的数据跟原来的大小保持不变
在4, 1x28x28这个reshape中是将通道和像素信息融合,比较适合最后的全连接层
![[Pasted image 20230508213241.png]]

我现在前3个维度合在一起
物理意义是所有照片的行和通道的数据信息合并,只关心这行数据
![[Pasted image 20230508213351.png]]

如果融合前2个维度合在一起
![[Pasted image 20230508213423.png]]
那就是代表只关心照片和通道数据

这种view操作的缺点
![[Pasted image 20230508213508.png]]
我们原本的顺序的bchw这个数据组合破坏了
重构出来的数据可能是bhwc或者是bchw等等都可能
![[Pasted image 20230508213608.png]]
![[Pasted image 20230508213628.png]]
所以我们如果使用view操作就需要保存原来的数据格式,避免数据污染掉

![[Pasted image 20230508213816.png]]
如果我们新的view操作跟原来的大小不一样,也会报错

**squeeze/unsqueeze**
挤压和展开可以看作减少和增加维度的操作

首先看unsqueeze
```python
a.shape
a.unsqueeze(0).shape

a.unsqueeze(-1).shape

a.unsqueeze(4).shape

a.unsqueeze(-5).shape

a.unqueeze(5).shape
```
![[Pasted image 20230508214139.png]]
现在存在a的shape如图所示
![[Pasted image 20230508214213.png]]
这行代码代表是在0维度前面插入一个维度
假如我们的4代表的是batch的维度,添加的一个维度1可能代表的是几组batch的物理意义
没有增加数据,只是额外增加1个组,组里面有4张图片
![[Pasted image 20230508214452.png]]
unsqueeze代表的是从哪个位置插入一个维度
![[Pasted image 20230508214530.png]]
![[Pasted image 20230508214521.png]]
注意unsqueeze是只能够拓展1作为增加维度的数值的,也就是增加一个理解的概念

index的取值范围是
![[Pasted image 20230508214640.png]]
不能够超过现有的维度,不然就会报错
![[Pasted image 20230508214720.png]]

核心在于增加现有数据的理解方式,不是增加数据
![[Pasted image 20230508214954.png]]
![[Pasted image 20230508215113.png]]

对图片处理的案例
```python
b = torch.rand(32)
f = torch.rand(4,32,14,14)
b = b.unsqueeze(1).unsqueeze(2).unsqueeze(0)
b.shape
```
![[Pasted image 20230508215235.png]]
![[Pasted image 20230508215249.png]]
这里的b代表的是bias,代表对每一个channel都添加一个偏差值
现在我如何将这个随机的bias对应的添加到每一个channel上
这里的随机初始化的 b 跟 f 的格式对应不上
f 的格式是 b c h w 的经典格式
所以需要吧b 也编程对应的格式
可以不按照代码这个固定的方式来,可以随意调换顺序

**squeeze**
维度删减
需要给一个index指定删减内容
```python
b.shape
b.squeeze().shape
b.squeeze(0).shape
b.squeeze(-1).shape
b.squeeze(1).shape
b.squeeze(-4).shape
```
![[Pasted image 20230509125744.png]]
此处的b代表的是
1张照片32个channel每张照片只有1x1的像素点
![[Pasted image 20230509125834.png]]
如果不指定挤压的维度
```python
a = torch.randn(2, 32, 1, 1)  
print(a.shape)  
print(a.squeeze().shape)  
# torch.Size([2, 32, 1, 1])  
# torch.Size([2, 32])
```
指定一个具体的维度
![[Pasted image 20230509132608.png]]
会发现0维度挤压了
我们再看
![[Pasted image 20230509132638.png]]
这个时候无法对于32这个维度挤压掉
但是如果是1作为维度的数值就可以挤压掉
所以squeeze就是删除张量中维度为1的轴

**维度扩展**
expand/repeat
ex
- expand: broadcasting
- repeat: memory copied

通过我之前对于b的展开操作,将dim1的张量变为了dim4的张量
![[Pasted image 20230509133115.png]]
expand是增加理解方式不是增加数据
repeat是拷贝增加数据

```python
a = torch.rand(4, 32, 14, 14)
b.shape
b.expand(4, 32, 14, 14).shape
b.expand(-1, 32, -1, -1).shape
b.expand(-1, 32, -1, -4).shape
```
扩张后的shape dim必须一致
![[Pasted image 20230509133527.png]]
而且扩张前的维度只能是1作为数值 因为算法无法先除再乘
假如图中的3 要变成 M 这样是不能够expand 会报错
![[Pasted image 20230509133819.png]]
如果我只想扩展其中一个维度,不扩展的维度就使用-1作为参数即可
![[Pasted image 20230509133804.png]]
之前还存在有bug
![[Pasted image 20230509133918.png]]
这里的负数倍数也是可以作为乘法的
![[Pasted image 20230509133946.png]]

**repeat**
```python
b.shape
b.repeat(4, 32, 1, 1).shape
b.repeat(4, 1, 1, 1).shape
b.repeat(4, 1, 32, 32).shape
```
![[Pasted image 20230509134722.png]]
变化就是重复对应维度的参数倍数
此时的dim需要对应原来的dim
![[Pasted image 20230509134814.png]]
repeat一般不使用,因为repeat因为是复制原来的数据,所以在内存上会把原来的数据更改掉

**矩阵转置操作**
```python
b.t()
a = torch.randn(3,4)
a.t()
```
![[Pasted image 20230509134948.png]]
.t 是一种方法只能使用2D 的tensor 也就是维度为2
对于其他dim的张量都无法使用
也就是对于矩阵独有的一个方法
![[Pasted image 20230509135123.png]]

**transpose**
更加广泛使用的矩阵维度交换操作
transpose方法的参数包含要交换的两个维度
```python
a.shape # [4,3,32,32]
a1 = a.transpose(1,3).view(4,3*32*32).view(4,3,32,32)
```
![[Pasted image 20230509135833.png]]
这样写代码会报错,因为源数据维度交换后, 然后将后3个维度合在一起看, 然后用view拆开
因为我们首先交换了  b c h w 这四个维度中的1 3 维度 这个时候内存已经改变了
变为了b w h c
后边的3个维度 whc相乘 变为了 b whc
这个时候要拆成 b c h w的形式是会造成图像失真的

例如，如果你有一个形状为(4, 3, 32, 32)的张量，表示4张RGB图像，每个通道有32x32个像素。如果你直接用view操作把它变成(4, 3072)，那么每一行就是一个图像的所有像素值，但是这些像素值的顺序是按照第一个通道，然后第二个通道，然后第三个通道排列的，而不是按照原来的空间位置排列的。这样就会导致图像失真，无法正确显示。

contiguous函数的原理是返回一个在内存中连续存储的张量，包含和原张量相同的数据。如果原张量在内存中不是连续存储的，那么contiguous函数会重新分配一块内存，并把原张量的数据按照指定的顺序复制过去。这样就可以保证张量的数据顺序和形状一致，方便进行view操作。

此时我们的修正后的代码变为
```python
a1 = a.transpose(1,3).contiguous().view(4,3*32*32).view(4,3,32,32)
```
这样修改还是有问题的
因为从 b c h w 经过transpose 变换为了 b w h c 然后用contiguous变为了bwhc
然后使用view 变为了b whc 这样再直接使用 4 3 32 32 同样的问题会产生数据污染
正确的方法如下
```python
a2 = a.transpose(1,3).contiguous().view(4,3*32*32).view(4,32,32,3).transpose(1,3)
```
前边的过程一样 拆开的过程中 4 32 32 3 也就是对应的 bwhc的维度数字
拆开之后再transpose一次就转换回去原来的样子

![[Pasted image 20230509141408.png]]
虽说图中显示的没有问题是同样的size, 但是实际a1的数据是污染掉的
我们可以使用eq函数来验证
a2 = a
但是 a1 ≠ a
```python
torch.all(torch.eq(a,a1))
torch.all(torch.eq(a,a2))
```
![[Pasted image 20230509141605.png]]
一定要跟踪住原图的维度,不然会污染掉数据
![[Pasted image 20230509141635.png]]

**permute函数**
```python
a = torch.rand(4,3,28,28)
a.transpose(1,3).shape
b = torch.rand(4,3,28,32)
b.transpose(1,3).shape
b.transpose(1,3).transpose(1,2).shape
b.permute(0,2,3,1).shape
```
假设原来的是 b c h w 的维度顺序
现在使用transpose 进行转置 变成了 b w h c
![[Pasted image 20230509142021.png]]
原图就会从原来的人 转变为新的样子
如果我现在需要保证原来的h和w的顺序一致 只把c这个因素放到最后去
![[Pasted image 20230509142222.png]]
实际意义就是能够再numpy中导出
从代码可以看出,如果我使用transpose实现这个功能 需要转置两次
![[Pasted image 20230509142345.png]]
如果使用permute
就只用一次
![[Pasted image 20230509142406.png]]
参数就是对应维度的数字
permute也是会打乱内存,所以遇到contiguous错误就需要使用 contiguous函数来让内存中重新生成一处连续的存储部分
