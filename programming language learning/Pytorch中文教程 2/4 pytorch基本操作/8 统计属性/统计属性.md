11- norm
- mean sum
- prod
- max，min，argmin，argmax
- kthvalue，topk

**范数**
norm
查看gradient的norm是否太大
norm不是normalize正则化
batch_norm这里代表的是正则

matrix norm和vector norm的区别
![[Pasted image 20230509194539.png]]

norm-p
```python
a = torch.full([8],1)
b = a.view(2,4)
c = a.view(2,2,2)
```
b c分别是
![[Pasted image 20230509194659.png]]
我们分别查看三个tensor的norm
```python
a.norm(1),b.norm(1),c.norm(1)
```
![[Pasted image 20230509194818.png]]
1 范数是所有的元素的绝对值求和
```python
a.norm(2),b.norm(2),c.norm(2)
```
2 范数是所有元素的平方和的绝对值求和然后开根号
![[Pasted image 20230509194931.png]]
```python
b.norm(1,dim=1)
b.norm(2,dim=1)
```
给定dim
b上面只有0和1两个维度
![[Pasted image 20230509195158.png]]
现在是再这个4维度做norm
所以结果就是 结果是数据
![[Pasted image 20230509195237.png]]
```python
c.norm(1,dim=0)
c.norm(2,dim=0)
```
c的0维度
![[Pasted image 20230509195519.png]]
可以看到取哪个维度的范数就会消去什么维度
![[Pasted image 20230509195658.png]]
这里就是消除掉了第0维度剩下的是2，2
这里的格式就是2行2列没有问题


**常见的统计属性**
mean sum min max prod
```python
a = torch.arange(8).view(2,4).float()
a.min(),a.max(),a.mean(),a.prod()
```
![[Pasted image 20230509195920.png]]
prod是累乘的意思
```python
a.sum()
a.argmax(),a.argmin()
```
用到最多的是max和min相关的这四个
![[Pasted image 20230509200154.png]]
可以看到这里提取到的函数结果不是1，3或者0，0
而是7和0
这是因为提取位置之前先将其打平之后再取出来位置
![[Pasted image 20230509200259.png]]
如果我们不希望打平而是希望某一个维度下面求min和max
我们必须给定维度
```python
a = a.view(1,2,4)
a.argmax()
a.argmin()
a = torch.rand(2,3,4)
a.argmax()
```
这些就是输出总是打平后的顺序
![[Pasted image 20230509200545.png]]

```python
a = torch.randn(4,10)
a[0]
a.argmax()
a.argmax(dim=1)
```
![[Pasted image 20230509200537.png]]
这里我们先生成了一个2D 的tensor 是4行10列的张量
首先提取出0维度向量是如图所示
整体的最大值，经过argmax定位是第18个元素，但是这是flatten之后的位置不是我们想要的
我们现在需要的是得出每一行的最大值出现的位置
我们可以类比成 一个问题
现在有4个结果需要输出 后边的10个数字代表这从哪里输出的概率
现在我们要得到这4个结果分别从哪次输出的概率是最高的位置
这里返回的是随机生成的2D tensor 在4行中出来的最大值的编号

如果我们这里的dim=0
返回的就是一整行数据


**dim keepdim的作用**
还是刚才的a 作为4，10的tensor
![[Pasted image 20230509205428.png]]
```python
a.max(dim=1)
a.argmax(dim=1)
```
![[Pasted image 20230509205544.png]]
返回的值就是4行的最大值 以及它们在的位置
用在实际应用问题上就是
4张照片的预测结果，十分类中的最大的结果是出现在什么类别
然后这个类别有一个值作为置信度
置信度高说明预测的准确

![[Pasted image 20230509205846.png]]
我们在使用dim1的时候就是会返回一个1行4列的tensor
所以就会变成【4】这样的tensor
但是我们为了后边的计算 我希望得出的tensor是4，1的形式
这样就可跟原来的对上
![[Pasted image 20230509210035.png]]
这个时候就可以使用keepdim
```python
a.max(dim=1,keepdim=True)
a.argmax(dim=1,keepdim=True)
```
![[Pasted image 20230509210118.png]]
如果这里不使用keepdim
那就需要最后unsqueeze一下变为原来的size
![[Pasted image 20230509210229.png]]

**前多少个的预测值**
topk or kthvalue
topk就会比max返回更多的数据
包含有最大值和最大值所在的位置
![[Pasted image 20230509210437.png]]
```python
a.topk(3,dim=1)
```
![[Pasted image 20230509210506.png]]
这时候函数有一个默认的值为largest=True
```python
a.topk(3,dim=1,largest=False)
```
这样就是求最小值
![[Pasted image 20230509210615.png]]
和topk的功能类似的是kthvalue
```python
a.kthvalue(8,dim=1)
```
![[Pasted image 20230509210749.png]]
这个代表的是第8小的是什么数值
这个默认是从最小开始算

**比较运算的操作**
- > >= < <=  !=  ==
- torch.eq(a,b)

```python
a>0
torch.gt(a,0)
```
![[Pasted image 20230509211035.png]]
对于每个元素进行和0对比
bytetensor作为存储方式返回的是整型
但是这里的0和1虽然是整型 但是代表的意思是是或者否

下面的一行代码也是一样的功能greater than前边比后边
![[Pasted image 20230509211250.png]]

```python
a != 0
```
就是不等于的意思
![[Pasted image 20230509211325.png]]
可以看到返回的全是 true

![[Pasted image 20230509211428.png]]
可以看到equal 和eq两个函数返回的一个是布尔值一个是bytetensor类型的数值
