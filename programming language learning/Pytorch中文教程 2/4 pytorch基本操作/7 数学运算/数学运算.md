- add/minus/multiply/divide
- matmul 矩阵相乘
- pow 次方
- sqrt/rsqrt 次方根
- round 近似运算

**矩阵的四则运算**
```python
a = torch.rand(3,4)
b = torch.rand(4)
# 因为有boardcasting的机制 所以可以直接相加 会自动扩展unsqueeze和expand

a + b
```
![[Pasted image 20230509183044.png]]
```python
torch.add(a,b)
torch.sub(a,b)
torch.mul(a,b)
torch.div(a,b)
```
![[Pasted image 20230509183134.png]]

我们可以检查一下使用直接运算和函数运算的结果数据是不是一样的
```python
torch.all(torch.eq(a-b, torch.sub(a,b)))
```
![[Pasted image 20230509183255.png]]
这里的结果1代表所有的都是eq的

同样可以检查一下其他的运算方法
```python
torch.all(torch.eq(a*b, torch.mul(a,b)))
torch.all(torch.eq(a/b, torch.div(a,b)))
```
![[Pasted image 20230509183451.png]]
所有结果都是一致的
![[Pasted image 20230509183510.png]]
所以建议直接使用运算符
两个除号代表是整除 就是求得的数字向下取整

**矩阵乘法**
matmul

python中* 代表的是element-wise 也就是元素相乘
还有一种是matrix mul 是矩阵相乘
两者是不一样的

矩阵相乘有两种表达形式
torch.mm 只适用于2D的tensor
torch.matmul
@分matmul是一样的
```python
a
b = torch.ones(2,2)
torch.mm(a,b)
torch.matmul(a,b)
a@b
```
一般使用matmul比较容易理解

一个例子
线性层的相加
```python
a = torch.rand(4,784)
x = torch.rand(4,784)
w = torch.rand(512,784)

(x@w.t()).shape
```
4张照片，然后向量打平之后形成4，784
中间就构造一个w矩阵把784 维度降到 512 维度
这里x@w.t() 就是这个降维过程
注意这里的.t 方法是只适用于2D的tensor
如果是其他维度需要用transpose

这个整体就形成了一个前向运算的流程

需要注意的是这里的torch中是默认为 512 是ch-out 而 784 是ch-in
这里的输出通道数代表的是卷积核的个数，也就是输出张量的深度
输入通道代表的是输入张量的深度

同样可以把512降维64
然后64降维10
这样十分类的前向运算就完成了

对于二维以上的矩阵相乘
```python
a = torch.rand(4,3,28,64)
b = torch.rand(4,3,64,32)

torch.mm(a,b).shape
```
这样计算会报错
![[Pasted image 20230509190844.png]]
```python
torch.matmul(a,b).shape
```
如果使用matmul是可以计算的
只取后边的两个维度计算
![[Pasted image 20230509191222.png]]
![[Pasted image 20230509191241.png]]
matmul函数是用来计算两个张量的矩阵乘积的。它的行为取决于张量的维度，具体如下：

-   如果两个张量都是一维的，那么返回它们的点积（标量）。
-   如果两个张量都是二维的，那么返回它们的矩阵乘积。
-   如果其中一个张量是一维的，另一个张量是二维的，那么返回一维张量和二维张量的矩阵向量乘积。
-   如果两个张量都是高于二维的，那么返回它们的批量矩阵乘积，即对齐最后两个维度进行矩阵乘积，其他维度保持不变。

```python
b = torch.rand(4,1,64,32)
torch.matmul(a,b).shape
```
我们把b更改一下 前面的size 更改为 4，1，64，32
这样后边的两个还是相乘
前边的两个看是否符合broadcast的规则，是符合的，所结果还是4，3，28，32
因为1 可以 扩展为3
![[Pasted image 20230509191827.png]]

```python
b = torch.rand(4,64,32)
torch.matmul(a,b).shape
```
这样子写代码就会报错
我们要注意是从右边开始对齐，后边两个矩阵是可以相乘
但是前边的矩阵补齐之后变为了1，4 这样 0维向量1是可以对应4的，但是1维向量4无法对应3 不符合broadcast的规则
![[Pasted image 20230509192038.png]]


**次方运算**
power
```python
pow(a, 2/3/4)
```
```python
a = torch.full([2,2],3)
a.pow(2)
```
![[Pasted image 20230509192327.png]]
创建了一个全是3的2x2矩阵，然后使用pow函数 2 代表二次方
还有另一种表示方法
```python
a**2
```
这个也可以表示二次方
![[Pasted image 20230509192417.png]]
```python
aa = a**2
aa.sqrt()
```
sqrt 代表是 square root 平方根
![[Pasted image 20230509192532.png]]
```python
aa.rsqrt()
```
这个表示平方根的倒数 这里是1/3
![[Pasted image 20230509192625.png]]
还有一种更简单的写法
```python
aa**2
aa**0.5
```
如果是0.5就代表开平方
一般还是使用pow的函数

**幂次方根**
```python
a = torch.exp(torch.ones(2,2))
a
torch.log(a)
```
第一行代码是先创造一个2x2的全为1的单位矩阵
然后exp代表是e作为底数作1次方
形成了全为e的矩阵
![[Pasted image 20230509192943.png]]

接下来是对a开log方 这里的默认是以1为底的log
![[Pasted image 20230509193021.png]]
所以就会变回去单位矩阵

**近似值**
- ,floor().ceil()
- .round()
- trunc().frac()
```python
a = torch.tensor(3.14)

a.floor(), a.ceil(), a.trunc(), a.frac()

a = torch.tensor(3.499)

a.round()

a = torch.tensor(3.5)

a.round()
```
floor 就是往下走预估 ceil 就是往上走预估
round 就是四舍五入预估
trunc 就是取整数值
tensor 就是取小数值
![[Pasted image 20230509193334.png]]

**裁剪功能**
- 梯度裁剪gradient clipping  需要打印w.grad.norm(2) 梯度的模 一般大于100就很大了 小于10 是合适的
```python
grad = torch.rand(2,3)*15
grad.max()
grad.median()
gram.clamp(10)
```
![[Pasted image 20230509193607.png]]
这里clamp后面的参数10 代表的是将最小值限定为10
![[Pasted image 20230509193639.png]]
这张图可以看到这里的4. 和8. 都变成了10
![[Pasted image 20230509193710.png]]
如果我们限定了一个范围，就会按照这个范围限定
前面是min 后边是max