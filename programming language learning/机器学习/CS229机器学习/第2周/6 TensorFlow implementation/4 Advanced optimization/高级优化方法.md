![[Pasted image 20230526151147.png]]
一步的梯度下降方法

可以使用adam optimizer 可以改变学习率为更大的值
在学习率下降比较小步幅的时候
![[Pasted image 20230526151337.png]]

或者遇到情况学习率比较大，在一定区域震荡
![[Pasted image 20230526151410.png]]

所以Adam算法可以帮助构成学习率
![[Pasted image 20230526151437.png]]

如果一个梯度下降的方向是朝着同一个方向的情况，adam算法可以增加学习率让其在梯度下降的方向上更快
如果梯度下降的过程是震荡的情况，adam算法可以减小学习率
![[Pasted image 20230526151656.png]]

使用tensorflow实现的方法
```python
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))
```

![[Pasted image 20230526160348.png]]
普通的hidden layer 中，下一层的神经元都是由上一层中的参数×输入得到的
当然还需要有激活函数

除了denselayer 还有 convolutional layer
从编程角度来看，是将神经元只注意到某一个区域的像素
这样可以更快的计算，需要更少的训练数据
![[Pasted image 20230526160941.png]]
对于心电图，每个波动出现的位置可以对应一个height
这样可以转换为一个向量
![[Pasted image 20230526161226.png]]
这个也是一个卷积层
代表着是从图片输入中获取一列中的一部分输入作为计算要素进入到卷积层中的神经元进行计算
下一层卷积层也是类似的情况
![[Pasted image 20230526161409.png]]
