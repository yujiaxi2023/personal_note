这里有一个训练集，包含有患者的年龄，肿瘤的大小，是否是恶性肿瘤等信息
这里有m个training examples，我们可以使用i= 1 2 3···给它们排序
![[Pasted image 20230430204509.png]]
一共设置这里有n个features
这里是一个二分类问题
所以target y 可以写成0或者1
![[Pasted image 20230430204613.png]]
使用逻辑回归方程sigmoid函数
现在我们使用均方误差函数作为损失函数
![[Pasted image 20230430204644.png]]
这个函数一般是作为线性函数这个只有一个低谷的碗形状的函数
![[Pasted image 20230430204719.png]]
![[Pasted image 20230430204730.png]]
但是我们现在的函数是sigmoid函数，**带入均方误差损失函数后他在图像上是非凸函数**，如图所示，这样的图没法一步步降低到最低点，所以有可能回陷入到局部最低点，然后不进行运算，这样是不好找到全局最低点的

这时候，我们需要一个新的函数
![[Pasted image 20230430204931.png]]
我们把这个每次计算产生的误差称为损失loss
![[Pasted image 20230430205047.png]]
我们现在只看loss function，这里的loss function是假设出来的，下面要证明为什么使用这个loss function是有意义的
![[Pasted image 20230430205239.png]]
这里就是图像函数
我们放大到0-1之间，这是我们关注的区间
![[Pasted image 20230430205334.png]]
我们可以看到当x轴取值越小的时候loss function越大，这是不好的
所以，当我们的取值是靠近1的时候，损失函数是更小的
使用-log函数的0-1之间的部分，作为y=1的时候的损失函数，误差更小

同样的道理对于y=0的时候
我们假设的这个函数就是如下图
![[Pasted image 20230430205621.png]]
同样是看0-1之间的取值
我么可以看到靠近0的值误差函数取值更小，所以这样更好
![[Pasted image 20230430205657.png]]
![[Pasted image 20230430205735.png]]
要注意到我们取值接近1的时候，取值是无线靠近无穷的，这时候损失函数取值很大，这样给到的惩罚是很大的
意味着，如果模型说这个患者的肿瘤很大可能是恶性的，但是实际上是良性的肿瘤，那就会给到一个很大的损失函数

**也就是当预测值和实际值相差越远，那损失函数就越高，这样在训练过程中就可以纠正这个错误的预测取值**

所以，采用这种损失函数，可以保证整体的cost function是凸状的，也就是保证相加的损失函数的每个值是随着越靠近正确值损失函数越小，这样整体函数取值的趋势是可以形成一个最低点的
![[Pasted image 20230430210406.png]]
![[Pasted image 20230430210436.png]]
上图就是将sigmoid函数带入均方误差损失函数的图像，如图所示会有很多的局部最小值
