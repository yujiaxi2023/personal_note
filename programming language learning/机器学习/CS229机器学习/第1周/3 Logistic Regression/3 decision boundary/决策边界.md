![[Pasted image 20230430195004.png]]
我们现在有两个步骤去形成一个logistic regression model
第一步
构建一个函数z 为向量w参数，和向量x测试集中数据点乘的值，然后加b作为偏置项
第二步
使用sigmoid函数g应用于z，函数的等式如上图表示

如果我们把这两步的函数带入，消掉中间函数
最后的结果可以写作
![[Pasted image 20230430195325.png]]
![[Pasted image 20230430195350.png]]
上方的式子是在二分类问题中的示例，也就是当二分类问题中y=1的情况下
现在我们要预测输入的值到底是输出y=1或者是y=0
一个常见的方式就是选择一个阈值threshold
![[Pasted image 20230430202741.png]]
从 函数图像可以看出，当z大于等于0的时候可以取大于等于0.5的值
![[Pasted image 20230430202908.png]]

我们在判断二分类问题中，会有一条特殊的边界就是z=0
当我们在一个简单的问题下
![[Pasted image 20230430203219.png]]
进行分类的时候，可以看出，这时候有两个参数影响着分类
当w参数，以及偏置项b确定的时候，我们就可以得到一条明确的决策边界
![[Pasted image 20230430203336.png]]
此时是w1和w2取值1 b取值-3
这样决策边界就可以看作是紫色的线条

如果我们不是简单的可以使用线性分类器划分的案例，也就是不能用简单的k近邻算法进行计算的时候
如图所示
![[Pasted image 20230430203451.png]]
这个时候x代表y取值1，⭕代表y取值为0
这个时候线性无法分类，我们尝试使用平方进行分类
![[Pasted image 20230430203616.png]]
这个时候的w和b取值如图所示
我们这个时候的决策边界就是
![[Pasted image 20230430203714.png]]
表现在图中就是一个圆
![[Pasted image 20230430203730.png]]

这种更复杂的分类方式，我们可以使用更高阶的函数进行拟合，看能否进行分类
![[Pasted image 20230430203827.png]]
逻辑回归可以拟合相当复杂的内容
