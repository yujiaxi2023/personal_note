![[Pasted image 20230422182256.png]]
我们可以通过这两个对比看到
如果我们的训练集的值是偏大的，我们的参数应该选择偏小的值，如果我们的训练集值是偏小的，我们选择的参数就应该大一些

![[Pasted image 20230422182559.png]]
我们可以从坐标轴的角度来看，xi的坐标轴数据都是集中在很长的区间内
所以可以看作x2的变化不敏感，x1的变化很敏感
一个小的x1的变化w1回影响价格很多，而一个大的x2的变化w2也不会产生非常大的变化

因为我们的学习率是固定的，在这个例子里面w1和w2的学习率设定的是一样的值，所以，在梯度下降的时候会来回进行震荡，如图所示
![[Pasted image 20230422183003.png]]
![[Pasted image 20230422183044.png]]
所以我们可以进行正则化，也就是rescaling 的过程把数据库变为一个更加圆形的样子，这样梯度下降的参数也能够下降的更加直接

![[Pasted image 20230422183741.png]]
第一种将数值平均化的方式是除以每个区间的上限

第二种方式是mean normalization均值归一化
我们需要求得数据集的平均值，然后用x-平均值/max-min值
这样可以让data均匀的区分在0的周边，正负值都有
![[Pasted image 20230422184031.png]]

最后一种是Z-score normalization比较常见
我们需要求得standard deviation标准差σ，还有平均值μ
使用x-平均值/标准差
![[Pasted image 20230422184315.png]]

并非是所有的feature都需要进行缩放
进行数据缩放几乎不会对机器学习产生影响
![[Pasted image 20230422184611.png]]
