学习曲线learning curve的横轴是训练集的数据多少
现在我们有一个模型是这样子的
![[Pasted image 20230616222448.png]]
![[Pasted image 20230616222501.png]]
绘制出来的学习曲线是这样的

从我们只有一个示例开始拓展到两个以上
在我们的数据量上升的时候，能够使用这个模型完美的拟合所有的数据将会越来越难，这样势必造成的结果是总体上的趋势training error将会变得越来越大
![[Pasted image 20230616222701.png]]

对于cross validation error一般来说会比training error更大，同样的，拟合的数据越多，在validation set上出现的误差就会越来越小，而同样的训练数据的不足会造成validation set的数据error也很大

首先我们分析一个high bias的欠拟合的示例
![[Pasted image 20230616222949.png]]
在示例不断提升的时候training error将会变得更平，因为更多的示例是将这个线性函数到后边变化将会非常微小
这个时候的baseline level performace 将会低于你的训练结果
这种情况下增加训练数据实际上是没有作用的，后边的training error 和validation error将会触到一个天花板不会继续降低到baseline level
![[Pasted image 20230616223310.png]]


现在一个high variance 的示例
这里的结果就是jcv会有一个巨大的gap和jtrain之中
但是这里增加示例是有用的，能够更加拟合我们的真实曲线
![[Pasted image 20230616223535.png]]
![[Pasted image 20230616223545.png]]
最开始的时候中间的差距很大，但是提高数据集就可能降低差距

在建立深度学习模型的时候，如果我们有1000个图片，可以选择100个看一下他们的学习曲线，来判断我们的模型的选择是bias还是variance出现问题
