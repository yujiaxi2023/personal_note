编程的第一步是CNN 也就是ResNet50模型获得每一个batch，然后添加positional encoding，然后添加一个transformer encoder
![[Pasted image 20230704142639.png]]
decoder 是初始化100个向量，这100个向量学习获得的坐标框进行bounding box和cls分类两种结果
![[Pasted image 20230704142828.png]]
其中encoder因为cnn将图片分为了很多个batch
![[Pasted image 20230704142847.png]]
这些 batch会在decoder 进行位置对应
每一种query跟前面输入的k1v1一直到最后一个内积的结果，看是不是有我这个query需要的结果，也就是attention的对象
![[Pasted image 20230704143036.png]]
这里的query是同时并行的进行对照的，这里100个query对应的是同时出结果
最后是连接一个全连接层，输出结果如果是bbox就是4个features
如果是cls就是80个features

encoder 得出的结果就是下图，会得出有哪些k1和v1的内积是值得注意的，可以让模型关注我们需要的物体
![[Pasted image 20230626161411.png]]
![[Pasted image 20230626161648.png]]
这里输入为100个向量，指定我应该关注哪些物体
学习每个向量关注的 特定的区域

一般情况是使用随机化来初始化，但是这里并不是
所有的向量用0来初始化，但是每个向量使用位置编码
规定你输入的object queries 关注的位置
