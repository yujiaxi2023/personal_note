**Lecture 02 Image Classification pipeline**

python+numpy实现k最近领和线性分类器
![[Pasted image 20230309193544.png]]
手机拍摄的照片是三通道的像素矩阵，像素值是0-255之间的数，我们会用8bit存储一个pixel，8bit可以存储2的8次方的数据，就是256个数据，也就是0-255之间的整数，一张图片就是由三个channel 也就是RGB构成的三个二维矩阵
![[Pasted image 20230309194358.png]]
```python
def classify_image(image):
	return class_label
```
深度学习中，是一个黑箱，这个原因是因为很难让计算机去从像素矩阵的方式去了解一个物体的意思，至少人类没有想出来是什么样的思考方式可以让计算机按照人类的逻辑去理解这个图片，所以深度学习就是首先给计算机大量的有这一性质的图片，让他自己可以识别其中的特征。
![[Pasted image 20230309195053.png]]
人类试图了解另外的识别猫的方式，就是从边界和点这种比较抽象也是计算机可以理解的方式去描述猫，但是这样提取出来的特征都非常模糊，而且是非常的没有效率
![[Pasted image 20230309195253.png]]
机器学习的数据驱动方法是深度学习的基础，首先需要获得带标签的照片，然后训练分类器，然后再新的图片，也就是测试集上预测

**First classifier：Nearest Neighbor最近邻**
![[Pasted image 20230309200705.png]]
这是一种惰性算法，其实不需要训练，直接在测试集中找到与训练集中最相似的就可以

example dataset：CIFAR 10
![[Pasted image 20230309201130.png]]
![[Pasted image 20230309201235.png]]
![[Pasted image 20230309201359.png]]
对应位置像素插值绝对值相加就是L1 distance![[Pasted image 20230309201610.png]]
L1距离就是两点之间这个三角形的两边的长度这样的意思，L1距离越小就说这两个图片差别越小
![[Pasted image 20230309202127.png]]
注意其中的代码是python2写的语法不一样，但是原理就是测试集和训练集的差值绝对值求和
右侧的问题是如果又N 个待检测的例子，或者是N个待训练的例子，那么所需要的时间分别是多少
	回答是，训练是只需要训练一个例子的时间，预测是需要N个例子线性增加的时间
	这不是我们需要的结果，我们需要的是训练时间可以很长，但是测试时间要尽可能的短暂
	但是最近邻也有好的应用例子，就是facebook中又利用最近邻计算的内容![[Pasted image 20230309202639.png]]
	![[Pasted image 20230309202714.png]]
	以黄点和绿点为例，其实就是求两点的垂直平分线，然后划分边界，落到什么颜色就离什么更近，其实这里可以看出表现不好的地方在于出现了橙色区域的噪点，也就是绿色区域的中间部分，还有就是边界太不平滑，不能generalize，泛化。

接下来就是引进K最近邻
![[Pasted image 20230309203043.png]]
也就是不只是看最近的一个数据而是看最近的3个或者是5个数据，让这几个进行majority vote，按照纯数量来进行加权，而这个K是一个超参数，不是越大越好，需要人为设定，K如果非常大，最后也许都在同一个分类下了
![[Pasted image 20230309203403.png]]
L2距离就是两个向量的差的平方求和，从图上看，就是L1距离对于旋转比较敏感，原点到方形的边的距离要保持相同的话，就需要方形跟着坐标轴旋转，而L2距离就不需要，L1距离是适用于描述的特征含义比较明确，例如员工绩效，迟到与否等，如果特征没有什么特别的含义，例如两者之间的距离
其实计算最近邻的时候还有其他的距离方式，例如闵氏距离Minkowski Distance，切比雪夫距离Chebyshev Distance等。闵氏距离是一种广义化的距离度量方式，当参数P等于1时，闵氏距离等价于曼哈顿距离，当P等于2时，闵氏距离等于欧几里得距离，当P趋于无穷大时，闵氏距离等价于切比雪夫距离
![[Pasted image 20230310160655.png]]
设置数据集时候，可以类比于考试，train中是平时的练习题，validation是模拟考试，test是最后的高考题
![[Pasted image 20230310160829.png]]
用枚举的方式把前面的训练数据集分为 等分，然后分别用其中的一个作为validation进行交叉验证，这样获得的分数是一个比较值得信赖的，五折交叉验证，十折交叉验证，二十折都有可能
![[Pasted image 20230310161746.png]]
使用L2距离使用最近邻计算，变化了的三张图片都是和原图一样，说明三张图在这种算法下面就是一张图
推荐系统中的近邻算法比较多

**Linear classification**
线性分类器在神经网络中是很有用的，二维空间就是
![[Pasted image 20230313143135.png]]
三维就是![[Pasted image 20230313143203.png]]
![[Pasted image 20230313143316.png]]
深度学习就像是搭积木，每个模块可以拆成小的模块，然后组成大的，如图所示
是描述一个图片的内容，这个流程就是首先使用卷积神经网络，然后再使用循环神经网络去识别图
![[Pasted image 20230313143859.png]]
首先图象是32x32x3通道的，可以看作是矩阵32x32x3的矩阵相乘是3072个数字，可以把每个像素向量乘以权重，就可以实现分类，W是斜率，还可以增加一个标量
![[Pasted image 20230313143936.png]]
权重是矩阵的行，像素是一列矩阵，计算出的数值加上截距就是猫的分数
![[Pasted image 20230313144658.png]]
异或门问题无法用直线分类，后边两类也是一样