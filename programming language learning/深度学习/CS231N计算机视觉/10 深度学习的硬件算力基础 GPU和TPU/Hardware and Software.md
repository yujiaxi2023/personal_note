![[Pasted image 20230330150728.png]]
硬件基础CPU GPU TPU
算力，数据和算法是深度学习的根本驱动力
**CPU**
计算机算力的中心Centrol Processing Unit
![[Pasted image 20230330151024.png]]
![[Pasted image 20230330151314.png]]
顶部是金属的封装盖，下方还有一个较小的保护盖，用于保护下方的芯片
![[Pasted image 20230330151355.png]]
![[Pasted image 20230330151455.png]]
![[Pasted image 20230330151508.png]]
芯片是焊接在电路板上
![[Pasted image 20230330151530.png]]
电路板背面是1200个金属触点
与主板上的 1200个针脚相互对应
半导体芯片中又很多的组成部分，最主要的是其中的10个核心
![[Pasted image 20230330151615.png]]
一个核心内部的结构是很复杂的
![[Pasted image 20230330151743.png]]
一个芯片中至少存在100亿个由纳米级别组成的晶体管
晶体管上是多层金属线，这就可以类比是一个公路网，可以达到每秒数十亿次的操作
![[Pasted image 20230330151859.png]]
![[Pasted image 20230330151954.png]]
多核芯片的中间是共享的三级缓存
![[Pasted image 20230330152019.png]]
中间是环形互联导线，右侧是集成显卡的显卡芯片
![[Pasted image 20230330152116.png]]
![[Pasted image 20230330152135.png]]
左上角是内存控制器，负责向内存条读取数据和发送数据
![[Pasted image 20230330152219.png]]
左侧是通信芯片，管理各个组件的数据交流

**主板**
![[Pasted image 20230330152256.png]]
主板是一块PCB电路板，内部集成了数千根金属导线
上面焊接了芯片，插座，插槽，端口和电线接口
![[Pasted image 20230330152438.png]]
主板右下角散热片下面 是主板的核心，是主板的芯片组
![[Pasted image 20230330152519.png]]
它专门由一条线路与CPU连接
![[Pasted image 20230330152549.png]]
这里是指最新的intel构架的12代主板
![[Pasted image 20230330152625.png]]
主板位于CPU旁边的是稳压器模块VRM，它的作用是将输入电压降低到1.32v然后给CPU使用
![[Pasted image 20230330152702.png]]
![[Pasted image 20230330152750.png]]
这些组件的使用率高达80%-90%
![[Pasted image 20230330152829.png]]
因此就需要散热器作为散热使用
![[Pasted image 20230330152909.png]]
其峰值功率可以达到130w左右
所以需要一个散热器来降温
![[Pasted image 20230330152932.png]]
![[Pasted image 20230330153016.png]]
水冷散热器实际上是通过液体的热交换给芯片散热，其组成部分如下
由控制芯片PCB板，转子，隔板，定子和叶轮

**电源**
为电脑供电的设备
![[Pasted image 20230330153207.png]]
主变压器和PCB控制板用于稳定电压，还有许多控制电流的组件
![[Pasted image 20230330153357.png]]
每个部件需要的电压值不一样，所以输出的电压就有不一样的去处
![[Pasted image 20230330155615.png]]
![[Pasted image 20230330155637.png]]
计算机的各个组件功耗的差距很大
![[Pasted image 20230330160225.png]]
GPU就需要一个12V的接口额外供电

**GPU**
![[Pasted image 20230330151102.png]]
图形计算，也就是显卡的芯片
![[Pasted image 20230330160400.png]]
散热片下是GPU芯片
![[Pasted image 20230330160424.png]]
![[Pasted image 20230330160441.png]]
![[Pasted image 20230330160449.png]]
芯片的周边是VRMA显存和VRM电源稳压模块
![[Pasted image 20230330160731.png]]
挡板的一侧是各种显示器的接口
![[Pasted image 20230330160747.png]]
下方是PCI-E插口
![[Pasted image 20230330160811.png]]
另一侧是额外供电电源的接口
显卡芯片的底部同样是连接到PCB板的1000多个接口
![[Pasted image 20230330160950.png]]
打开封装盖后是芯片的结构
有100多亿个晶体管，分成6个图形处理集群和28个图形处理器
![[Pasted image 20230330161204.png]]
![[Pasted image 20230330161310.png]]
每个图形处理器是由128个核心构成
![[Pasted image 20230330161339.png]]
因此总共由3584个核心
![[Pasted image 20230330161355.png]]
每个核心分为运算部分和用于管理的部分，因此比CPU的结构简单很多
![[Pasted image 20230330161457.png]]
![[Pasted image 20230330161529.png]]
图形处理器周围 各有一个共享二级缓存
![[Pasted image 20230330161612.png]]
周围是与显存交换数据的内存控制器和一个PCIE的接口控制器
![[Pasted image 20230330161700.png]]
![[Pasted image 20230330161724.png]]
其中排列的是和CPU相关的晶体管，以及多层金属导线，GPU由数千个核心组成，但是只能进行简单的运算，但是CPU是由10个核心进行较为复杂的计算
CPU具备分析单元，运算单元，代码执行单元等等

**内存条**
![[Pasted image 20230330162031.png]]
CPU是直接通过主板上的内存通道，直接与内存条交换数据，内存条的8个芯片中，由32个内存库组成，每个库由8192列，65536行
![[Pasted image 20230330162105.png]]
![[Pasted image 20230330162125.png]]![[Pasted image 20230330162221.png]]
但是内存条最多能短时间存世16GB的数据，而且断电之后就会消失
如果我们要长时间存储数据就需要迁移到固态硬盘或者是机械硬盘中
![[Pasted image 20230330162358.png]]
![[Pasted image 20230330162406.png]]
机械硬盘是通过磁头在磁盘中移动，访问50万磁道中的单个磁道
![[Pasted image 20230330162500.png]]
写入数据是通过磁头改变磁道中的磁极单个方向实现，读取就是磁头感应磁盘上的方向，内存条的读写速度最快，但是没有办法储存，机械硬盘储存量非常大，但是读写速度很慢

![[Pasted image 20230330163209.png]]
CPU的浮点运算速度是比GPU要慢两个数量级
![[Pasted image 20230330163427.png]]
让卷积变为 矩阵的乘法就可以让GPU进行计算
利用im2col将卷积转换为向量也就是矩阵运算
![[Pasted image 20230330163816.png]]
当达到7nm以下时晶体管之间存在量子现象的干扰，所以晶体管的数量是达到极限的，采用GPU是一个改进的方式，也大大增加了浮点运算的次数
![[Pasted image 20230330163940.png]]
cuDNN可以在GPU的基础上加速运算的速度
![[Pasted image 20230330164042.png]]
TPU是谷歌开发的专用于机器学习的硬件，显存可以看作是一个仓库，计算的瓶颈在于仓库和运算之间的通路
![[Pasted image 20230330164256.png]]
CUDA类似于一个工作台，是加速神经网络运算的工具，利用C语言编写
![[Pasted image 20230330164411.png]]
数据是硬盘和GPU之间传输的
![[Pasted image 20230330164441.png]]
解决办法是从将数据写入内存，将机械硬盘换位固态硬盘
也可以使用多个CPU线程读取数据
![[Pasted image 20230330164719.png]]
利用多个GPU也可以进行数据并行加速模型的训练
![[Pasted image 20230330164800.png]]
左侧是数据并行，右侧是模型并行
![[Pasted image 20230330164848.png]]
为了加速模型的训练，我们需要在GPU进行前向和反向传播的时候用CPU去读取多个进程数据
去取得新的数据
![[Pasted image 20230330165126.png]]
四种芯片的特化功能
![[Pasted image 20230330165532.png]]
显卡需要看显存容量显存位宽和显存频率，显存位宽代表叉车的数量，频率代表的速度

**TPU**
![[Pasted image 20230330165857.png]]
特化计算架构可以提高运算速率
![[Pasted image 20230330170031.png]]
![[Pasted image 20230330170226.png]]
神经网络的工作原理
![[Pasted image 20230330170249.png]]
首先分块
![[Pasted image 20230330170327.png]]
然后变为每个区域的数据进行矩阵相乘
![[Pasted image 20230330170348.png]]
得出结果后整合到一起得出一个数值，这个数值是属于什么数字的就是什么内容
![[Pasted image 20230330170425.png]]
![[Pasted image 20230330170457.png]]
在CPU中就是单独取出某一块进行计算后得出结果然后取下一块，所以计算效率比较低
![[Pasted image 20230330170541.png]]
在GPU中就是由很多个类似CPU的模块进行计算
![[Pasted image 20230330170642.png]]
![[Pasted image 20230330170652.png]]
最后就能够同时得出一列结果
![[Pasted image 20230330170717.png]]
![[Pasted image 20230330170734.png]]
把分类器的权重行中，这样在计算的时候就可以直接把权重拆开之后放到这些个空座位中
在进行测试的时候就把测试图像也同样的拆开放到对应的列之中
![[Pasted image 20230330170902.png]]
![[Pasted image 20230330170952.png]]
![[Pasted image 20230330171010.png]]
TPU采用的是可以将一个节点的参数和所有的参数同时共享，相比于CPU需要通过一个终端处理 数据后传回到原来的模块中，更高效
![[Pasted image 20230330171329.png]]
![[Pasted image 20230330171410.png]]
tensorflow中可以直接调用这个TPU
![[Pasted image 20230330171454.png]]
在resnet模型上表现是线性增加的
![[Pasted image 20230330171537.png]]
TPU做到了让某个节点只掌握一个权重，而不是一个节点掌握所有的权重，这样可以有益于简单的计算，也就是深度学习
![[Pasted image 20230330171715.png]]
机器学习的跑分