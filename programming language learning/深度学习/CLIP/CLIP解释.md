Contrastive language-image pre-training
利用文本的监督信号训练一个迁移能力强的视觉模型

clip原来是imagenet中使用的效果很少
open ai使用大量的数据产生了结果

检查万物是否能够想GPT一样，对于视觉任务也是一样的
是使用4亿个配对的数据和文本来进行训练，不标注直接爬取的数据
CLIP下游任务很多，gan，检测，分割检索都能玩

如何训练模型
- 图像编码器
- 文本编码器
- 计算余弦相似度
- 对角线的是正样本
![[Pasted image 20240123211646.png]]

这里文本特征要跟图片提取出来的特征相似度是最高的
需要要给对比学习，正样本是图片和描述都是狗，负样本就是两个不匹配的情况

文本转特征其实就是用GPT已经有很好的benchmark了

如何inference
- 给出prompt
- 提示好好说话
- 每种计算相似度
- 找到概率最高的内容

![[Pasted image 20240123212118.png]]

就是算文本和图片的相似度，找到相似度最高的一个

openai没有提供训练模型的代码，只提供了预训练模型
